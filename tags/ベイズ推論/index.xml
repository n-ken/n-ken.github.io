<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ベイズ推論 on Garbage in, garbage out</title>
    <link>https://n-ken.github.io/tags/%E3%83%99%E3%82%A4%E3%82%BA%E6%8E%A8%E8%AB%96/</link>
    <description>Recent content in ベイズ推論 on Garbage in, garbage out</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sun, 02 Jul 2017 16:43:22 +0900</lastBuildDate>
    
	<atom:link href="https://n-ken.github.io/tags/%E3%83%99%E3%82%A4%E3%82%BA%E6%8E%A8%E8%AB%96/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>StanとRでベイズ統計モデリングの第4章をPyMC3で実装</title>
      <link>https://n-ken.github.io/2017/07/stan%E3%81%A8r%E3%81%A7%E3%83%99%E3%82%A4%E3%82%BA%E7%B5%B1%E8%A8%88%E3%83%A2%E3%83%87%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%AE%E7%AC%AC4%E7%AB%A0%E3%82%92pymc3%E3%81%A7%E5%AE%9F%E8%A3%85/</link>
      <pubDate>Sun, 02 Jul 2017 16:43:22 +0900</pubDate>
      
      <guid>https://n-ken.github.io/2017/07/stan%E3%81%A8r%E3%81%A7%E3%83%99%E3%82%A4%E3%82%BA%E7%B5%B1%E8%A8%88%E3%83%A2%E3%83%87%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%AE%E7%AC%AC4%E7%AB%A0%E3%82%92pymc3%E3%81%A7%E5%AE%9F%E8%A3%85/</guid>
      <description>「StanとRでベイズ統計モデリング」を読みました。ベイズ統計モデリングを行うための様々なテクニックがや具体的な事例が紹介されていて、とても勉強になりました。
本書はrstanを使ってモデリングしています。pystanを使った実装例も様々なブログで紹介されているのですが、PyMC3についてはほとんど情報がありませんでした。
そこで、このブログではPyMC3での実装例を紹介していこうと思います。
単回帰モデル 年齢から年収を予測する単回帰モデルを構築します。具体的には以下の通りです。(モデルについては書籍をご参照下さい)
$$ \begin{aligned} y_i &amp;amp;\sim \text{Normal}(a + bx_i, \sigma^2)\cr a &amp;amp;\sim \text{Normal}(0, 100^2)\cr b &amp;amp;\sim \text{Normal}(0, 100^2) \end{aligned} $$
コースコードの確認 問題設定やモデル式などは、書籍を参考にしてください。以下のコードは、PyMC3で実装したサンプルです。
 モデル定義 まずはモデル定義部分を説明します。PyMC3では、モデル定義をwith文の中で行います。with pm.Model()はおまじないのようなものだと思っていただいて大丈夫です。
モデリングの手順は、事前分布を定義し、尤度関数を指定し、サンプリング方法を指定します。
事前分布 確率変数がクラスとして定義されているので、そちらを使用して事前分布を定義します(a, b, sigma)。決定論的に決まる変数は、pm.Deterministicを用いてインスタンス化すると、サンプリングの対象となります。
尤度関数 確率変数クラスのobserved引数にデータを渡すと、その変数は観測値を持つため、尤度関数となります。比較的シンプルに使い分けることができます。
サンプリング方法 pm.sampleでサンプリング方法を指定します。パラメーターが連続値の場合、デフォルトではNUTSを使用し、離散値の場合はM-H法を使用します。ここでは、3000サンプルを取得しています。色々と指定できるので、詳しい使い方は公式ドキュメントを参考にしてください。
収束診断 収束診断のpm.traceplotは、サンプリング列をグラフで表示してくれます。また、pm.gelman_rubinで\(\hat{R}\)を計算してくれます。グラフで見たい場合は、pm.forestplotで可視化できます。
予測分布の計算 予測分布を得たい場合は、pm.sample_ppcを使用します。データを変更したい場合がほとんどかと思いますので、その場合はtheano.sharedを使用してモデル定義を行って下さい。今回の場合は、xをそのようにしています。set_valueメソッドで値をセットしなおしてからpm.sample_ppcを実行すれば、予期した結果が得られます。
予測分布は以下のようになります。
  まとめ PyMC3で、4章のポイントとなる部分を実装しました。Pythonだけで記述できるところが、PyMC3を使う良いところですね。
どのライブラリや言語を使うかは手段の問題なので、使いやすいものを利用してベイズ推論に慣れていくと良いと思います。使いやすいものを使って、是非本書の内容をマスターしていきたいものです。</description>
    </item>
    
  </channel>
</rss>